{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WPSR Query Using PySpark\n",
    "\n",
    "The following query will use the PySparkSQL engine to read and perform a\n",
    "query on Reporters contained within the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from os.path import expanduser\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Reading file ..: wsprspots-2020-02.parquet\n",
      "* File Size .....: 490,259,730 bytes compressed\n",
      "* Read Time .....: 1.51541 sec\n",
      "\n",
      "* Counting Records\n",
      "* Record Count ..: 47,310,649\n",
      "* Count Time ....: 0.89148 sec\n",
      "\n",
      "* Running Group by Count Query and return the dataframe\n",
      "+--------+------+\n",
      "|Reporter| count|\n",
      "+--------+------+\n",
      "|   DK6UG|838081|\n",
      "|  OE9GHV|690104|\n",
      "|  EA8BFK|648670|\n",
      "|   KD2OM|589003|\n",
      "|KA7OEI-1|576788|\n",
      "|   K4RCG|571445|\n",
      "|     KPH|551690|\n",
      "|    K9AN|480759|\n",
      "|   DF5FH|480352|\n",
      "|   DJ9PC|474211|\n",
      "|  HB9TMC|472900|\n",
      "|    ND7M|461383|\n",
      "|  IW2NKE|455781|\n",
      "|    WO7I|437582|\n",
      "|   ON5KQ|427628|\n",
      "|  N6GN/K|361590|\n",
      "|  WA2ZKD|328003|\n",
      "|  KJ6MKI|318174|\n",
      "|   LX1DQ|309909|\n",
      "|   W2GNN|308290|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "* Query Time ....: 4.89078 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple function to get file size\n",
    "def getSize(filename):\n",
    "    st = os.stat(filename)\n",
    "    return st.st_size\n",
    "\n",
    "\n",
    "# File location and size variables\n",
    "# Adjust the path as needed\n",
    "home_dir = expanduser(\"~\")\n",
    "parquet_file = os.path.join(home_dir, 'Dev/Data/wspr/wsprspots-2020-02.parquet')\n",
    "file_size = getSize(parquet_file)\n",
    "\n",
    "\n",
    "# Setup the Spark Cluster Config Variables\n",
    "conf = SparkConf().setAppName(\"Radio Data Science - WSPR Read Tests\").setMaster(\"local[*]\")\n",
    "\n",
    "\n",
    "# Instantiate the Spark Session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Radio Data Science - Parquet Test\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Print some basic headers and process the file\n",
    "print(f'\\n* Reading file ..: {os.path.basename(parquet_file)}')\n",
    "print(f'* File Size .....: {file_size:,} bytes compressed')\n",
    "start = time.time()\n",
    "df = spark.read.load(parquet_file, format=\"parquet\")\n",
    "end = time.time()\n",
    "print(f\"* Read Time .....: {round((end-start), 5)} sec\")\n",
    "\n",
    "\n",
    "# This is a second trip through the file to get a total count\n",
    "print(f'\\n* Counting Records')\n",
    "start = time.time()\n",
    "print(f'* Record Count ..: {df.count():,}')\n",
    "end = time.time()\n",
    "print(f\"* Count Time ....: {round((end-start), 5)} sec\")\n",
    "\n",
    "\n",
    "# This is a group by aggregate for the top 20 by count\n",
    "print(f'\\n* Running Group by Count Query and return the dataframe')\n",
    "start = time.time()\n",
    "df2 = df.groupBy('Reporter').count().orderBy('count', ascending=False).show(20)\n",
    "end = time.time()\n",
    "print(f\"* Query Time ....: {round((end-start), 5)} sec\\n\")\n",
    "\n",
    "# Shutdown the PySpark engine.\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
